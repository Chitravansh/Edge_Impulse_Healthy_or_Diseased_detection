# ğŸŒ¿ LeafGuard â€” Edge AI Plant Leaf Health Detector (Android | Offline TFLite)

LeafGuard is a real-time, offline, on-device Android prototype that classifies plant leaf health into **Healthy** or **Diseased**, using a compact TensorFlow Lite model exported via Edge Impulse and powered by CameraX for real-time camera capture.

---

## ğŸšœ Realâ€‘World Problem

Farmers often lack fast AIâ€‘powered tools that can instantly analyze leaf health **without internet**. This leads to:

* Delayed diagnosis
* Limited accessibility in rural areas
* Dependence on cloud solutions

**Goal:** Provide instant, offline, mobileâ€‘based leaf health detection using edgeâ€‘inference on Android.

---

## âœ… MVP â€” Whatâ€™s Implemented

âœ” Offline inference (2â€‘class image classifier)
âœ” Live camera preview + capture using CameraX
âœ” TFLite model execution directly on device
âœ” Prediction + confidence score display
âœ” Works on emulator/phone for quick testing

---

## ğŸ§  AI/ML Implementation Summary

1. Model trained (prototype 2â€‘class dataset) using Edge Impulse Studio
2. Model exported as `plant_disease_model.tflite`
3. Labels mapped to model output order in `label.txt`
4. Camera frames converted from `ImageProxy` (YUV) â†’ `Bitmap` â†’ model input
5. App loads `.tflite` + `label.txt` from **assets/** for inference

---

## ğŸ“ Required Assets Included

Place the following under:

```
app/src/main/assets/
â”œâ”€â”€ plant_disease_model.tflite
â””â”€â”€ label.txt
```

`label.txt` must match model output order. Example:

```
healthy
diseased
```

---

## âš™ï¸ Tech Stack

| Component                 | Technology               |
| ------------------------- | ------------------------ |
| Language                  | Kotlin                   |
| UI                        | Jetpack Compose          |
| Camera                    | CameraX                  |
| ML Runtime                | TensorFlow Lite          |
| ML Studio/Export          | Edge Impulse             |
| Edge Inference Device     | Android Phone / Emulator |
| Code Hosting (submission) | GitHub                   |

---

## ğŸ“± How to Test on Android Phone (Edge Device)

1. Open project in Android Studio
2. Connect phone via USB
3. In phone, enable:

    * Developer Options
    * USB Debugging
    * File Transfer (PTP/MTP)
4. Run â–¶ from Android Studio
5. Grant **Camera Permission**
6. Capture/Pan a real leaf â†’ view classification result + confidence

---

## ğŸ” Sample Output (for reference)

```
Prediction: Healthy
Confidence: 73.0 %
```

---

## âš  Current Prototype Limitations

* 2â€‘class model only (`Healthy` / `Diseased`)
* Not cropâ€‘wise or diseaseâ€‘specific yet
* Dataset kept small for a **quick edgeâ€‘deployment MVP demo**

---

## ğŸ”® Future Scope (Not part of MVP)

* Multiâ€‘crop and diseaseâ€‘specific detection
* Larger field datasets
* AIâ€‘based treatment suggestions
* Model optimizations for lowâ€‘power edge hardware

---

## â­ Why LeafGuard is an Edge AI Solution

* Inference runs **on device** (Android = edge hardware)
* ML model exported from Edge Impulse to TFLite
* No cloud dependency at runtime
* Camera is used as the realâ€‘time sensor input to ML pipeline
* Works fully **offline with minimal latency**

---

## ğŸ‘¨â€ğŸ’» Author

**Chitravansh**
Participant â€” HackerEarth Ã— Edge Impulse Edge AI Contest

---

## ğŸ“Œ Tags

`Edge AI` Â· `Onâ€‘Device ML` Â· `Offline Inference` Â· `Android Kotlin` Â· `TFLite` Â· `CameraX` Â· `Agriculture AI Prototype` Â· `Hackathon MVP`

---

â­ If this helped, feel free to star the repo to support AIâ€‘atâ€‘edge innovation!
